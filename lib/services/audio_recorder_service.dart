import 'dart:async';
import 'dart:developer';
import 'dart:io';
import 'package:record/record.dart';
import 'package:path_provider/path_provider.dart';

class AudioRecorderService {
  final AudioRecorder _recorder = AudioRecorder();
  final StreamController<double> _amplitudeController =
      StreamController<double>.broadcast();
  String? _filePath;
  String? recordedFilePath;
  bool isRecording = false;
  StreamSubscription<RecordState>? _stateSubscription;
  StreamSubscription<Amplitude>? _amplitudeSubscription;

  /// **ğŸ“Š æŒ¯å¹…ãƒ‡ãƒ¼ã‚¿ã®ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’å–å¾—**
  Stream<double> get amplitudeStream => _amplitudeController.stream;

  /// **ğŸ¤ éŒ²éŸ³é–‹å§‹**
  Future<void> startRecording() async {
    try {
      final bool hasPermission = await _recorder.hasPermission();
      if (!hasPermission) {
        throw Exception("éŒ²éŸ³ã®è¨±å¯ãŒã‚ã‚Šã¾ã›ã‚“");
      }

      final directory = await getApplicationDocumentsDirectory();
      final recordingsDir = Directory("${directory.path}/recordings");
      if (!recordingsDir.existsSync()) {
        recordingsDir.createSync(recursive: true);
      }

      _filePath =
          "${recordingsDir.path}/recording_${DateTime.now().millisecondsSinceEpoch}.m4a";

      log("ğŸ¤ éŒ²éŸ³é–‹å§‹æº–å‚™: $_filePath");

      // âœ… éŒ²éŸ³é–‹å§‹ã‚’éåŒæœŸå‡¦ç†ã«ã—ã¦ UI ã‚’ãƒ–ãƒ­ãƒƒã‚¯ã—ãªã„
      _recorder
          .start(
        RecordConfig(encoder: AudioEncoder.aacLc),
        path: _filePath!,
      )
          .then((_) {
        log("ğŸ¤ éŒ²éŸ³é–‹å§‹: $_filePath");
        isRecording = true;
        recordedFilePath = null;

        // âœ… `onStateChanged` ã§éŒ²éŸ³ã®çŠ¶æ…‹ã‚’ç›£è¦–
        _stateSubscription?.cancel();
        _stateSubscription = _recorder.onStateChanged().listen((state) {
          if (state == RecordState.record) {
            log("ğŸ¤ éŒ²éŸ³ä¸­...");
          }
        });

        // âœ… `onAmplitudeChanged()` ã®ä¿®æ­£ï¼ˆéåŒæœŸã§å‡¦ç†ï¼‰
        Future.delayed(const Duration(milliseconds: 500), () {
          _amplitudeSubscription?.cancel();
          _amplitudeSubscription = _recorder
              .onAmplitudeChanged(const Duration(milliseconds: 100))
              .listen((event) {
            double amplitude = event.current;

            // ğŸ¯ è² ã®å€¤ã‚’æ­£è¦åŒ–ï¼ˆ0-1ã®ç¯„å›²ã«å¤‰æ›ï¼‰
            double normalizedAmplitude = (amplitude + 160) / 160;

            log("ğŸ“Š æŒ¯å¹…ãƒ‡ãƒ¼ã‚¿å—ä¿¡: ${event.current} â†’ æ­£è¦åŒ–: $normalizedAmplitude");
            _amplitudeController.add(normalizedAmplitude);
          }, onError: (e) {
            log("âŒ æŒ¯å¹…ãƒ‡ãƒ¼ã‚¿ã‚¨ãƒ©ãƒ¼: $e");
          });
        });
      }).catchError((e) {
        log("âŒ éŒ²éŸ³é–‹å§‹ã‚¨ãƒ©ãƒ¼: $e");
      });
    } catch (e) {
      log("âŒ éŒ²éŸ³é–‹å§‹ã‚¨ãƒ©ãƒ¼ï¼ˆtry-catchï¼‰: $e");
    }
  }

  /// **ğŸ›‘ éŒ²éŸ³åœæ­¢**
  Future<void> stopRecording() async {
    try {
      String? filePath = await _recorder.stop();
      log("ğŸ¤ éŒ²éŸ³åœæ­¢: $filePath");

      isRecording = false;
      if (filePath != null) {
        recordedFilePath = filePath;
      }

      // âœ… ã‚¹ãƒˆãƒªãƒ¼ãƒ è³¼èª­è§£é™¤
      await _stateSubscription?.cancel();
      _stateSubscription = null;
      await _amplitudeSubscription?.cancel();
      _amplitudeSubscription = null;
    } catch (e) {
      log("âŒ éŒ²éŸ³åœæ­¢ã‚¨ãƒ©ãƒ¼: $e");
    }
  }

  /// **ğŸ¤ ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’é–‰ã˜ã‚‹**
  void dispose() {
    _stateSubscription?.cancel();
    _amplitudeSubscription?.cancel();
    _amplitudeController.close();
  }
}
